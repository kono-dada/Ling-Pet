# LingPet 整体功能与架构概览（通俗版）

本文用尽量直白的话，介绍 LingPet 目前具备的功能，以及两个很重要的“底层机制”：心跳 + 定时任务（Schedule），还有“事件发射 + 插件响应”的扩展体系。读完后，你应该能大致明白：桌宠在做什么、什么时候做、以及它是如何被扩展成更聪明的小伙伴的。

**内容结构**
- 1. 整体功能介绍（概览）
- 2. 心跳与 Schedule 机制（重点）
- 3. 事件发射与插件响应（重点）

---

## 1. 整体功能介绍

- 智能聊天：支持与“灵灵”流畅对话，能边想边说（流式输出），还会配合表情变化。
- 语音合成：可选接入 Style-Bert-Vits2，把日语台词合成语音播放，像在和“会说话”的桌宠互动。
- 屏幕分析：能“看到”你屏幕上新出现的窗口，自动进行理解，再给出合适的回应（例如新开了文档或网页）。
- 细腻的表现：头像会随情绪变化（高兴、思考、无语等），UI 里也有呼吸/抖动等动效。
- 跨平台：基于 Tauri，Windows / macOS / Linux 都能跑。
- 设置与开关：常见功能都在设置里可开关，比如自动播放语音、屏幕分析开关、语音服务自动启动等。

如果把 LingPet 想象成一个“温柔但有主见的小伙伴”，那上面这些就是它能做的“日常技能”。下面两节讲“它的作息规律”和“它如何听见世界上的事情并作出反应”。

---

## 2. 心跳与 Schedule 机制

这一机制解决的问题是：
- 怎么规划未来要执行的任务？
- 电脑重启了，提醒还会不会丢？
- 同一时间不要“同时做两件事”，避免打断正在说的话。

核心思路是“心跳”+“任务状态机”。

- 心跳：每隔一段固定时间（默认 15 秒）醒来一次，检查有没有到点的任务；如果当前“空闲”，就挑一个任务执行。
- 任务状态机：每个任务从“已计划”到“待执行/过期”，再到“执行中”，最后“完成或取消”。这让任务的生命周期清清楚楚，随时可恢复。

你可以把它理解成：闹钟每 15 秒看一眼“提醒清单”，如果灵灵没有在说话，就从最着急的那条开始处理。

一个小例子（文字流程）
1) 你或 AI 调用一个工具，添加“30 分钟后提醒喝水”的任务。
2) 15 秒一次的心跳扫描到“到点”→ 把它从 `scheduled` 标为 `pending`。
3) 如果灵灵空闲，就把它置为 `running` 并调用 `onTask`，灵灵用自然的话“提醒你喝水”。
4) 说完后记上“完成”→ `accomplished`。如果超过“最后期限”还没说，就会走 `onOutdated` 分支给出补救式的提醒。

这个机制让“提醒类”的功能既可靠（不丢）、又不打扰（不打断），同时可扩展（过期怎么处理、挑选策略怎么换，都能改）。

---

## 3. 事件发射与响应 plugins 机制

这一机制解决的问题是：
- 桌宠如何“听见”外部世界的变化（比如屏幕上新开了窗口、头像被连点、长时间没人理）？
- 怎么让“听见的人”和“做事的人”解耦（方便扩展、开关、维护）？

核心思路是“事件总线 + 强类型 + 插件化处理”。

通俗一点的流程
1) 某个地方“发现了事情”，就“广播一条事件”。例如：
   - 每 5 秒扫描一次屏幕窗口，发现新窗口 → 广播 `NEW_WINDOWS`。
   - 用户在头像上快速连点几次 → 广播 `AVATAR_MULTI_CLICK`。
   - 很久没互动了 → 广播 `NO_INTERACTION_TIMEOUT`。
2) 全局“处理器管理器”根据开关，给这些事件“挂上或摘下”对应的处理函数。
3) 真正做事的是“插件”的处理函数：
   - 屏幕分析插件收到 `NEW_WINDOWS` → 截图识别 + 生成合适的回复（会流式说话）。
   - 交互插件收到 `AVATAR_MULTI_CLICK` → 注入几句示例台词/触发特定行为。

---

以上就是 LingPet 目前的整体功能与两大关键机制。简单说：
- 心跳 + Schedule 让“定时提醒类”的行为靠谱、可恢复、不打扰；
- 事件 + 插件让桌宠能听见外界并聪明回应，而且非常容易扩展。
